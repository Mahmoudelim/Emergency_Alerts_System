# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xbTJS3mlMKcHWtJ03bkiTYXjxlxgg0Hj
"""

from google.colab import files
import pandas as pd
import io
import joblib
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import FunctionTransformer
import numpy as np
from sklearn.metrics import classification_report

# Read the data
uploaded = files.upload()
df = pd.read_excel(io.BytesIO(uploaded['dd.xlsx']))
X = df.iloc[:, :-1]
y = df.iloc[:, -1]
y = y.str.upper()
y.unique()
print(y.head())

# Transformation: Apply a logarithmic transformation to a skewed feature
log_transformer = FunctionTransformer(func=np.log1p, validate=False)
X['HeartRate Log'] = log_transformer.transform(X['Heart Rate (BPM)'])
log_transformer = FunctionTransformer(func=np.log1p, validate=False)

print(X.head())
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)

# Create the pipeline
pipeline = make_pipeline(
    StandardScaler(),
    RandomForestClassifier(n_estimators=100, random_state=42)
)

# Fit the pipeline on the training data
pipeline.fit(X_train, y_train)

# Evaluate the model on the testing data
y_pred = pipeline.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy on the testing data:", accuracy)

# Evaluate the model on the training data
y_pred_train = pipeline.predict(X_train)
accuracy_train = accuracy_score(y_train, y_pred_train)
print("Accuracy on the training data:", accuracy_train)

# Classification Report on the testing data
report = classification_report(y_test, y_pred)
print("Classification Report on the testing data:\n", report)
import os
print(os.getcwd())

joblib.dump(pipeline, '/content/trained_model.pkl')


files.download('/content/trained_model.pkl')
# Function to classify severity for a given record
# Function to classify severity for a given record
# Function to classify severity for a given record
def classify_severity(record):
   # Check if the number of columns in the record matches the dataset


    # Create a DataFrame with the input record
    record_df = pd.DataFrame([record], columns=X.columns)

    # Apply the same transformations as in the training data
    record_df['HeartRate Log'] = log_transformer.transform(record_df['Heart Rate (BPM)'])
    record_df['DBP Log'] = log_transformer.transform(record_df['Diastolic Blood Pressure (mmHg)'])
    print(record_df)
    # Predict the severity
    predicted_severity = pipeline.predict(record_df)

    return predicted_severity[0]